# 4.9 LLM과 생성 AI — 반도체 산업의 새로운 도구

## 이 챕터에서 배우는 것
- LLM(Large Language Model)의 반도체 산업 적용 가능성
- 공정 지식 검색과 Q&A — 엔지니어의 AI 어시스턴트
- 자동 보고서 생성 — 수율 보고, 이상 분석 보고
- 코드 생성 — 분석 스크립트, 레시피 변환
- 멀티모달 AI — 이미지+텍스트+데이터의 통합 분석
- 보안과 한계 — 팹 환경에서의 LLM 운용

---

## LLM은 반도체에서 무엇을 할 수 있는가: 올바른 포지셔닝

이전 챕터들에서 다룬 VM, APC, FDC, 웨이퍼맵 분류 등은 모두 **정량적 예측/분류** 문제였다 — 센서 데이터를 입력받아 CD를 예측하고, 이미지를 입력받아 결함 유형을 분류하는. 이것은 LLM의 역할이 **아니다**. LLM은 "CD = 21.3nm"를 예측하는 데 쓰이지 않는다.

LLM의 가치는 **사람과 시스템 사이의 인터페이스**에 있다.

```
LLM ≠ VM/APC/FDC 대체
LLM = 엔지니어의 생산성 도구 (지식 검색, 보고서, 코드, 대화형 인터페이스)
```

이 포지셔닝을 명확히 한 위에서, LLM이 반도체에서 어떤 구체적 가치를 만들 수 있는지 살펴보겠다.

---

## 공정 지식 검색과 Q&A: 수십 년의 지식을 즉시 접근

### 문제: 지식의 사일로

팹에는 수십 년간 축적된 방대한 지식이 있다. 수천 페이지의 장비 매뉴얼과 공정 SOP, 과거 이상 분석 보고서와 트러블슈팅 기록, 엔지니어 개인의 경험을 담은 위키/노트, 그리고 가장 귀한 — 베테랑 엔지니어의 암묵지. 하지만 이 지식이 **사일로화**되어 접근이 어렵다. 신입 엔지니어가 "Ring 패턴이 나오면 어디를 점검해야 하나?"를 알려면 선배를 찾아다녀야 하고, 선배가 야근 중이면 다음 날까지 기다려야 한다.

### RAG 기반 공정 Q&A

**RAG(Retrieval-Augmented Generation)**은 이 문제를 해결한다.

```mermaid
flowchart LR
    subgraph RAG 기반 공정 Q&A
        Q[엔지니어 질문<br/>"Ring 패턴 원인은?"] --> RETR[검색<br/>매뉴얼, 과거 보고서<br/>트러블슈팅 기록]
        RETR --> LLM_GEN[LLM 생성<br/>관련 문서 기반<br/>답변 생성]
        LLM_GEN --> ANS[답변 + 출처<br/>"Ring 패턴은 주로<br/>핫플레이트 온도 불균일이<br/>원인입니다. [보고서 #2024-0847]"]
    end
```

파이프라인은 네 단계다. 팹 문서(매뉴얼, SOP, 과거 보고서, 트러블슈팅 기록)를 **벡터 DB**(Chroma, Pinecone 등)에 임베딩하여 인덱싱한다. 질문이 들어오면 의미적으로 **관련 문서를 검색**(Retrieval)한다. 검색된 문서와 질문을 LLM에 전달하여 **답변을 생성**한다. 답변에 **출처(Source)**를 함께 제공하여 엔지니어가 검증할 수 있게 한다.

이것이 단순한 키워드 검색과 근본적으로 다른 점은 — "Ring 불량"이라고 검색하지 않아도 "웨이퍼 가장자리에서 동심원 형태로 수율이 떨어지는 현상"이라고 질문하면 관련 문서를 찾아온다는 것이다. **의미적 검색(Semantic Search)**이 키워드 매칭의 한계를 넘는다.

가치는 명확하다 — 엔지니어 온보딩 시간이 수 개월에서 수 주로 단축되고, 베테랑 지식이 조직 자산으로 전환되며, 야간/주말에도 즉시 답변이 가능하다.

---

## 자동 보고서 생성: 반복 작업에서 해방

팹 엔지니어의 시간 중 상당 부분이 **보고서 작성**에 소요된다. 일일 수율 보고, 이상 분석 보고, 주간/월간 리뷰 — 데이터를 모으고, 정리하고, 해석하고, 문서화하는 반복 작업이다.

LLM은 구조화된 데이터(수율 DB, 이상 로그, 웨이퍼맵 분류 결과)와 보고서 템플릿을 입력받아, 자연어 초안을 생성한다.

```
[일일 수율 보고 - 2026-02-14]

전체 수율: 93.2% (전일 94.1% 대비 -0.9%p)

주요 이슈:
1. 식각기 ET-03에서 Edge 패턴 불량 증가 (+15 다이/웨이퍼)
   - 추정 원인: PM 이후 에지 가스 유량 불안정
   - 과거 유사 사례: 2025-11-23 (ET-01, 동일 증상 → 가스 유량 재교정으로 해결)
   - 권고: 에지 가스 유량 재교정

2. 스캐너 SC-07의 Overlay Y 방향 Drift 감지
   - 현재 3σ = 2.8nm (규격 3.0nm, 여유 7%)
   - 권고: 모니터링 강화, 필요 시 보정 갱신
```

핵심은 LLM이 **초안을 생성**하고, 엔지니어가 **검토/수정** 후 배포한다는 것이다. 완전 자동이 아닌 **증강(Augmentation)**이다. 보고서 작성 시간이 2시간에서 30분으로 줄어도 엄청난 생산성 향상이며, 특히 과거 유사 사례를 RAG로 자동 연결하는 것이 큰 가치다.

---

## 코드 생성: 데이터 분석의 민주화

### 자연어 → 분석 스크립트

엔지니어가 "지난주 스캐너 A의 CD vs Dose 상관 그래프 그려줘"라고 말하면, LLM이 Python 스크립트를 생성한다. 엔지니어가 Python을 몰라도 데이터 분석이 가능해진다.

### 자연어 → SQL (Text-to-SQL)

"이번 달 수율이 90% 이하인 로트를 장비별로 보여줘" → SQL 쿼리 자동 생성. 데이터 분석의 **민주화** — SQL을 모르는 공정 엔지니어도 데이터에 직접 접근할 수 있다. 3.8장에서 데이터 인프라의 복잡성을 다뤘는데, LLM이 이 복잡성을 **자연어 인터페이스로 추상화**하는 역할을 한다.

---

## 멀티모달 AI: 이미지와 텍스트를 함께 이해한다

**Vision-Language Model(VLM)**은 이미지와 텍스트를 동시에 처리한다.

**SEM 이미지 + 자연어 질의** — "이 SEM 이미지에서 결함이 보이나요? 어떤 유형인 것 같나요?"라고 물으면 VLM이 이미지를 분석하고 자연어로 답변한다.

**웨이퍼맵 + 컨텍스트 분석** — 웨이퍼맵 이미지와 장비 이력을 함께 제시하여 "이 패턴은 무엇이고, 과거 유사 사례에서 원인이 무엇이었나?"를 물을 수 있다.

**문서 내 다이어그램 이해** — 장비 매뉴얼의 배관도, 전기 회로도를 이해하고 설명할 수 있어, RAG의 품질을 향상시킨다.

현재 VLM의 반도체 이미지 분석 성능은 4.6장의 전문 CNN 모델에 미치지 못한다. 하지만 **학습되지 않은 새로운 유형의 결함**에 대한 비정형 분석, 빠른 프로토타이핑, 엔지니어와의 대화형 탐색 분석에서 가치가 있다.

---

## AI 에이전트: 미래의 자율 분석 시스템


![AI 에이전트 아키텍처 — Tool-Using Agent](https://image-proxy.jenghun-suh.workers.dev/images/04_09/tool_using_agent_architecture.svg)

LLM의 가장 흥미로운 활용은 **도구 사용 에이전트(Tool-Using Agent)**로의 확장이다.

```
엔지니어: "오늘 수율이 떨어진 원인을 분석해줘"

에이전트:
1. YMS에서 수율 데이터 조회        → (Tool: SQL Query)
2. 불량 패턴 분석                  → (Tool: 웨이퍼맵 분류기 호출)
3. 관련 장비 FDC 이상 확인          → (Tool: FDC 이상 탐지 호출)
4. 과거 유사 사례 검색              → (Tool: RAG 검색)
5. 종합 분석 보고서 생성            → (LLM 생성)

→ "ET-03 장비의 에지 가스 유량 이상이 주원인으로 추정됩니다.
    과거 2025-11에도 유사 사례가 있었으며..."
```

에이전트는 자연어 질문을 받아, **어떤 도구를 어떤 순서로 호출할지 스스로 결정**하고, 결과를 종합하여 답변한다. Part 3~4에서 다룬 모든 ML 모델(VM, APC, FDC 이상 탐지, 웨이퍼맵 분류기)이 에이전트의 **도구(Tool)**로 사용되는 것이다.

현재 기술로도 가능한 수준에 가까워지고 있으며, **SMILE 플랫폼에 에이전트 인터페이스를 내장**하면 경쟁 우위가 될 수 있다 — 엔지니어가 대시보드를 클릭하며 데이터를 찾는 대신, 자연어로 "왜?"라고 물으면 시스템이 알아서 분석하는 미래다.

---

## 보안과 한계: 솔직한 평가

### 팹 환경의 LLM 운용


![On-Premise vs Cloud LLM 비교](https://image-proxy.jenghun-suh.workers.dev/images/04_09/onpremise_vs_cloud_llm.svg)

**클라우드 LLM(GPT-4, Claude 등)** — 팹 데이터를 외부 서버에 전송할 수 없다(영업 비밀, 고객 NDA). 반도체 교과서 수준의 일반 지식이나 코드 생성에는 활용 가능하지만, 팹 내부 데이터와 결합하면 안 된다.

**On-Premise LLM(Llama, Mistral 등)** — 팹 내부에서 운영하여 데이터 유출이 없다. 팹 데이터로 Fine-Tuning하여 도메인 특화가 가능하다. 다만 모델 크기 제약으로 성능이 클라우드 모델보다 낮을 수 있고, GPU 인프라 투자가 필요하다. 4.5장의 On-Premise 배포 원칙이 LLM에도 동일하게 적용된다.

### LLM의 네 가지 한계

**할루시네이션(Hallucination)** — 그럴듯하지만 틀린 답을 생성한다. "Ring 패턴의 원인은 레티클 결함입니다"라고 자신 있게 말하지만 실제로는 핫플레이트 문제일 수 있다. 반도체 공정에서 잘못된 트러블슈팅 가이드는 시간 낭비를 넘어 추가 불량을 유발할 수 있다. RAG로 팩트 기반 답변을 유도하고, 출처를 반드시 제공하며, **인간 검토를 필수화**한다.

**정량적 정확도 부족** — "CD = 21.3nm"같은 정확한 수치 예측은 VM의 역할이지 LLM의 역할이 아니다. LLM은 "CD가 높아질 가능성이 있습니다" 수준의 정성적 판단은 가능하지만, 0.1nm 단위의 정량적 예측은 불가능하다.

**실시간 부적합** — LLM 추론은 수백 밀리초~수 초가 걸린다. APC의 밀리초 레이턴시 요구에는 사용할 수 없다. LLM은 오프라인 분석과 보고서 생성에 적합하고, 실시간 제어는 전통 ML(XGBoost, EWMA)의 영역이다.

**도메인 특화 지식 부족** — 공개 LLM은 반도체 공정의 세부 지식(특정 장비의 PM 절차, 특정 제품의 레시피 노하우)이 제한적이다. Fine-Tuning이나 RAG가 필수적이며, 팹 문서의 품질과 양이 RAG의 성능을 결정한다.

---

## 핵심 정리

LLM은 VM/APC를 대체하는 것이 아니라 **엔지니어의 생산성 도구이자 시스템 인터페이스**로 포지셔닝된다. **RAG 기반 Q&A**는 팹 문서를 벡터 DB로 인덱싱하여 수십 년의 지식에 즉시 접근하게 하며, 엔지니어 온보딩을 단축하고 베테랑 지식을 조직 자산화한다. **자동 보고서**는 데이터를 자연어 초안으로 변환하여 엔지니어의 반복 작업을 줄이고, **코드 생성/Text-to-SQL**은 데이터 분석의 민주화를 실현한다. **AI 에이전트**는 Part 3~4의 모든 ML 모델을 도구로 결합하여 자연어 질문에 자율적으로 분석하는 미래이며, SMILE 플랫폼의 경쟁 우위가 될 수 있다. 팹 보안상 **On-Premise LLM이 필수**이며, 할루시네이션/정량적 한계를 인식하고 **인간 검토를 필수화**한다.

---

*다음 챕터: 4.10 Part 4 종합 실습 — SMILE 파이프라인 설계*
